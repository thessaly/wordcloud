---
title: "Wordcloud with R"
output: html_notebook
---

## 1. Loading file and data

```{r}
# Read the text file 
filePath <- "example.txt"
text <- readLines(filePath)

# Load the data as a tibble
library(dplyr)
text_df <- tibble(line = 1:15, text = text)
```
## 2. Tokenizing

```{r}
library(tidytext)

token_df <- text_df %>%
            unnest_tokens(word, text)

token_df
```
## 3. Removing generic stopwords

```{r}
data(stop_words)

clean_df <- token_df %>%
  anti_join(stop_words, by = c("word" = "word"))

```

## 4. Removing stopwords defined by me
```{r}
mystop <- read.csv("stop.csv", header = TRUE)

cleaner_df <- clean_df %>%
  anti_join(mystop, by = c("word" = "text"))

cleaner_df
```
## 5. Getting word count
```{r}
frequency <- cleaner_df %>%
              count(word, sort = TRUE) 
```

## 6. Plotting

### Version A
```{r}
library(wordcloud)

frequency %>%
 with(wordcloud(word, n, min.freq = 5, max.words = 100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
```

### Version B
```{r}
library(wordcloud2)
```

```{r}
  wordcloud2(data=frequency, size=1.6, color='random-dark')
```








