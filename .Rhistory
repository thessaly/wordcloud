# Install
install.packages("tm")  # for text mining
install.packages("SnowballC") # for text stemming
install.packages("wordcloud") # word-cloud generator
# Load
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a corpus
docs <- Corpus(VectorSource(text))
inspect(docs)
toSpace <- content_transformer(function (x , pattern ) gsub(pattern, " ", x))
docs <- tm_map(docs, toSpace, "/")
docs <- tm_map(docs, toSpace, "@")
docs <- tm_map(docs, toSpace, "\\|")
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("Julieta", "Julian"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
docs <- tm_map(docs, removeWords, c("Julieta", "Julian","julian"))
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
text_df <- tibble(line = 1:71, text = text)
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a corpus
library(dplyr)
text_df <- tibble(line = 1:71, text = text)
text_df
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a tibble
library(dplyr)
text_df <- tibble(line = 1:71, text = text)
library(tidytext)
install.packages("tidytext")
library(tidytext)
text_df %>%
unnest_tokens(word, text)
tidy_books <- tidy_books %>%
anti_join(stop_words)
data(stop_words)
tidy_books <- tidy_books %>%
anti_join(stop_words)
data(stop_words)
tidy_books <- tidy_books %>%
anti_join(stop_words)
data(stop_words)
text_df <- text_df %>%
anti_join(stop_words)
data(stop_words)
text_df <- text_df %>%
anti_join(stop_words, by = c("word" = "word"))
data(stop_words)
data(stop_words)
data
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by= c("word" = "word"))
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by= c(word = "word"))
data(stop_words)
clean_df <- text_df %>%
anti_join(data, by= c(word = "word"))
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by = c("word" = "word"))
data(stop_words)
clean_df <- text_df %>%
anti_join(., sw, by = c("word" = "word"))
data(stop_words)
clean_df <- text_df %>%
anti_join(., stop_words, by = c("word" = "word"))
View(text_df)
View(text_df)
View(stop_words)
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by = c("text" = "word"))
View(clean_df)
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a tibble
library(dplyr)
text_df <- tibble(line = 1:71, text = text)
library(tidytext)
text_df %>%
unnest_tokens(word, text)
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by = c("text" = "word"))
View(clean_df)
data(stop_words)
clean_df <- text_df %>%
anti_join(stop_words, by = c("text" = "word"))
clean_df
library(tidytext)
token_df %>%
unnest_tokens(word, text)
library(tidytext)
text_df %>%
unnest_tokens(word, text)
library(tidytext)
token_df <- text_df %>%
unnest_tokens(word, text)
library(tidytext)
token_df <- text_df %>%
unnest_tokens(word, text)
token_df
data(stop_words)
clean_df <- token_df %>%
anti_join(stop_words, by = c("text" = "word"))
View(token_df)
data(stop_words)
clean_df <- token_df %>%
anti_join(stop_words, by = c("word" = "word"))
clean_df
data(stop_words)
clean_df <- token_df %>%
anti_join(stop_words, by = c("word" = "word"))
data("stop.csv")
clean_df <- token_df %>%
anti_join(stop_words, by = c("word" = "word"))
clean_df
data("stop.csv")
cleaner_df <- clean_df %>%
anti_join(stop_words, by = c("word" = "word"))
cleaner_df
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("text" = "word"))
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("word" = "text"))
cleaner_df
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("word" = "text"))
cleaner_df
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a tibble
library(dplyr)
text_df <- tibble(line = 1:71, text = text)
library(tidytext)
token_df <- text_df %>%
unnest_tokens(word, text)
token_df
data(stop_words)
clean_df <- token_df %>%
anti_join(stop_words, by = c("word" = "word"))
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("word" = "text"))
cleaner_df
cleaner_df %>%
count(word, sort = TRUE)
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("word" = "text"))
cleaner_df
cleaner_df %>%
count(word, sort = TRUE)
library(ggplot2)
cleaner_df %>%
count(word, sort = TRUE) %>%
filter(n > 600) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
library(ggplot2)
cleaner_df %>%
count(word, sort = TRUE) %>%
filter(n > 20) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col() +
xlab(NULL) +
coord_flip()
library(ggplot2)
cleaner_df %>%
count(word, sort = TRUE) %>%
library(ggplot2)
cleaner_df %>%
count(word, sort = TRUE)
frequency <- cleaner_df %>%
count(word, sort = TRUE)
library(scales)
# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
facet_wrap(~author, ncol = 2) +
theme(legend.position="none") +
labs(y = "Jane Austen", x = NULL)
library(scales)
# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = proportion, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme(legend.position="none") +
labs(y = "Jane Austen", x = NULL)
View(frequency)
library(scales)
# expect a warning about rows with missing values being removed
ggplot(frequency, aes(x = n, y = `Jane Austen`, color = abs(`Jane Austen` - proportion))) +
geom_abline(color = "gray40", lty = 2) +
geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
scale_x_log10(labels = percent_format()) +
scale_y_log10(labels = percent_format()) +
scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
theme(legend.position="none") +
labs(y = "Jane Austen", x = NULL)
library(wordcloud)
frequency %>%
with(wordcloud(word, n, max.words = 100))
library(wordcloud)
frequency %>%
with(wordcloud(word, n, min.freq = 10, max.words = 100))
library(wordcloud)
frequency %>%
with(wordcloud(word, n, min.freq = 5, max.words = 100))
library(wordcloud)
frequency %>%
with(wordcloud(word, n, min.freq = 5, max.words = 100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
wordcloud2(data=frequency, size=1.6, color='random-dark')
install.packages("wordcloud2)
library(wordcloud2)
wordcloud2(data=frequency, size=1.6, color='random-dark')
install.packages("wordcloud2)
library(wordcloud2)
wordcloud2(data=frequency, size=1.6, color='random-dark')
install.packages("wordcloud2")
library(wordcloud2)
wordcloud2(data=frequency, size=1.6, color='random-dark')
install.packages("wordcloud2")
library(wordcloud2)
cloud <- wordcloud2(data=frequency, size=1.6, color='random-dark')
cloud <- wordcloud2(data=frequency, size=1.6, color='random-dark')
cloud <- wordcloud2(data=frequency, size=1.6, color='random-dark')
# Read the text file from internet
filePath <- "stirlingnlp.txt"
text <- readLines(filePath)
# Load the data as a tibble
library(dplyr)
text_df <- tibble(line = 1:71, text = text)
library(tidytext)
token_df <- text_df %>%
unnest_tokens(word, text)
token_df
data(stop_words)
clean_df <- token_df %>%
anti_join(stop_words, by = c("word" = "word"))
mystop <- read.csv("stop.csv", header = TRUE)
cleaner_df <- clean_df %>%
anti_join(mystop, by = c("word" = "text"))
cleaner_df
frequency <- cleaner_df %>%
count(word, sort = TRUE)
library(wordcloud)
frequency %>%
with(wordcloud(word, n, min.freq = 5, max.words = 100, random.order=FALSE, rot.per=0.35, colors=brewer.pal(8, "Dark2")))
install.packages("wordcloud2")
library(wordcloud2)
cloud <- wordcloud2(data=frequency, size=1.6, color='random-dark')
install.packages("wordcloud2")
